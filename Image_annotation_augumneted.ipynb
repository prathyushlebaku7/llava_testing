{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented images and annotations are organized and zipped in: /Users/lebakuprathyushkumarreddy/Desktop/augmented_images.zip\n"
     ]
    }
   ],
   "source": [
    "#image annotations with images\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imgaug.augmenters as iaa\n",
    "from skimage import io\n",
    "from skimage.io import imsave\n",
    "import zipfile\n",
    "\n",
    "# Path to your images\n",
    "image_path = '/Users/lebakuprathyushkumarreddy/Desktop/testing_images'\n",
    "image_files = [os.path.join(image_path, f'image{i+1}.jpg') for i in range(10)]\n",
    "annotations =['Yes','yes','yes','yes','yes','yes','yes','yes','yes','yes'] \n",
    "\n",
    "# Image Augmentation\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5), \n",
    "    iaa.Crop(percent=(0, 0.1)),  \n",
    "    iaa.LinearContrast((0.75, 1.5)), \n",
    "    iaa.Multiply((0.8, 1.2))\n",
    "])\n",
    "\n",
    "images = [io.imread(f) for f in image_files]\n",
    "augmented_images = []\n",
    "augmented_annotations = []\n",
    "\n",
    "augmented_image_path = '/Users/lebakuprathyushkumarreddy/Desktop/augmented_images/images'\n",
    "augmented_annotation_path = '/Users/lebakuprathyushkumarreddy/Desktop/augmented_images/annotations'\n",
    "os.makedirs(augmented_image_path, exist_ok=True)\n",
    "os.makedirs(augmented_annotation_path, exist_ok=True)\n",
    "\n",
    "#augmented images and annotations\n",
    "for img_index, (img, annotation) in enumerate(zip(images, annotations)):\n",
    "    images_aug = seq(images=[img] * 50)  # Generate 50 augmented images\n",
    "    for aug_index, aug_img in enumerate(images_aug):\n",
    "        image_filename = f'aug_image_{img_index}_{aug_index}.jpg'\n",
    "        annotation_filename = f'aug_image_{img_index}_{aug_index}.txt'\n",
    "        image_filepath = os.path.join(augmented_image_path, image_filename)\n",
    "        annotation_filepath = os.path.join(augmented_annotation_path, annotation_filename)\n",
    "        imsave(image_filepath, aug_img)\n",
    "        with open(annotation_filepath, 'w') as file:\n",
    "            file.write(annotation)\n",
    "\n",
    "# Zipping augmented images and annotations\n",
    "zip_path = '/Users/lebakuprathyushkumarreddy/Desktop/augmented_images.zip'\n",
    "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "    # Add images\n",
    "    for root, _, files in os.walk(augmented_image_path):\n",
    "        for file in files:\n",
    "            zipf.write(os.path.join(root, file), arcname=os.path.join('images', file))\n",
    "    # Add annotations\n",
    "    for root, _, files in os.walk(augmented_annotation_path):\n",
    "        for file in files:\n",
    "            zipf.write(os.path.join(root, file), arcname=os.path.join('annotations', file))\n",
    "\n",
    "print(f'Augmented images and annotations are organized and zipped in: {zip_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab code\n",
    "\n",
    "pip install -q -U transformers==4.37.2\n",
    "pip install -q bitsandbytes==0.41.3 accelerate==0.25.0\n",
    "\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import pipeline\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "\n",
    "pipe = pipeline(\"image-to-text\", model=model_id, model_kwargs={\"quantization_config\": quantization_config})\n",
    "\n",
    "folder_path_images = '/content/drive/MyDrive/augmented_images/images'\n",
    "folder_path_annotations = '/content/drive/MyDrive/augmented_images/annotations'\n",
    "\n",
    "# List all image files\n",
    "image_paths = [os.path.join(folder_path_images, f) for f in os.listdir(folder_path_images) if f.endswith('.jpg')]\n",
    "\n",
    "questions = [\n",
    "    \"Question 1: <image> Is he wearing hard hat? \\nASSISTANT:\",\n",
    "]\n",
    "\n",
    "predictions = []\n",
    "ground_truths = []\n",
    "\n",
    "for image_path in image_paths:\n",
    "    image = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Corresponding annotation file\n",
    "    base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    annotation_file = f\"{folder_path_annotations}/{base_filename}.txt\"\n",
    "\n",
    "    # Read the ground truth annotation\n",
    "    with open(annotation_file, 'r') as file:\n",
    "        ground_truth = file.read().strip().lower()\n",
    "        ground_truths.append(ground_truth)\n",
    "\n",
    "    for question in questions:\n",
    "        outputs = pipe(image, prompt=question, generate_kwargs={\"max_new_tokens\": 200})\n",
    "        generated_text = outputs[0][\"generated_text\"]\n",
    "        assistant_response = generated_text.split(\"\\nASSISTANT:\")[1].strip()\n",
    "\n",
    "        first_word = assistant_response.split()[0].replace(',', '').lower() if assistant_response else \"no response\"\n",
    "        print(first_word)\n",
    "        predictions.append(first_word)\n",
    "\n",
    "# Calculating the metrics\n",
    "accuracy = accuracy_score(ground_truths, predictions)\n",
    "precision = precision_score(ground_truths, predictions, pos_label='yes')\n",
    "recall = recall_score(ground_truths, predictions, pos_label='yes')\n",
    "f1 = f1_score(ground_truths, predictions, pos_label='yes')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
